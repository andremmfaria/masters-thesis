@misc{Smith_NMF_Dataset_2024,
  author       = {Smith, Robert G},
  title        = {Smith\_NMF\_Dataset\_V1.0.0},
  year         = {2024},
  howpublished = {\url{https://doi.org/10.5281/zenodo.10639554}},
  note         = {Accessed 28-08-2024}
}

@phdthesis{Smith2023PhD,
  title  = {Exploiting Association Rules Mining to Inform the Use of Non-Manual Features in Sign Language Processing},
  author = {Smith, Robert G.},
  school = {Technological University Dublin, Ireland},
  year   = {2023}
}

@phdthesis{Smith2014MScThesis,
  title  = {The role of emotional and facial expression in synthesised sign language avatars},
  author = {Robert G. Smith},
  year   = {2014},
  type   = {{Masters} thesis},
  school = {Institute of Technology Blanchardstown, Ireland}
}

@inproceedings{smith2010hci,
  title     = {{HCI for the Deaf} community: Developing human-like avatars for sign language synthesis},
  author    = {Smith, Robert G. and Morrissey, Sara and Somers, Harold},
  booktitle = {Proceedings of the 4th {I}rish Human Computer Interaction Conference, Dublin},
  pages     = {129-136},
  year      = {2010}
}

@article{smith2016emotional,
  title     = {Emotional facial expressions in synthesised sign language avatars: a manual evaluation},
  author    = {Smith, Robert G. and Nolan, Brian},
  journal   = {Universal Access in the Information Society},
  volume    = {15},
  number    = {4},
  pages     = {567-576},
  year      = {2016},
  publisher = {Springer}
}

@misc{brown2020languagemodelsfewshotlearners,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.14165}
}

@article{10.1162/daed_a_01905,
  author   = {Manning, Christopher D.},
  title    = {Human Language Understanding \&amp; Reasoning},
  journal  = {Daedalus},
  volume   = {151},
  number   = {2},
  pages    = {127-138},
  year     = {2022},
  month    = {05},
  abstract = {The last decade has yielded dramatic and quite surprising breakthroughs in natural
              language processing through the use of simple artificial neural network computations,
              replicated on a very large scale and trained over exceedingly large amounts of data. The
              resulting pretrained language models, such as BERT and GPT-3, have provided a powerful
              universal language understanding and generation base, which can easily be adapted to many
              understanding, writing, and reasoning tasks. These models show the first inklings of a
              more general form of artificial intelligence, which may lead to powerful foundation models
              in domains of sensory experience beyond just language.},
  issn     = {0011-5266},
  doi      = {10.1162/daed_a_01905},
  url      = {https://doi.org/10.1162/daed\_a\_01905},
  eprint   = {https://direct.mit.edu/daed/article-pdf/151/2/127/2060607/daed\_a\_01905.pdf}
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.11401}
}

@misc{zou2024poisonedragknowledgecorruptionattacks,
  title         = {PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models},
  author        = {Wei Zou and Runpeng Geng and Binghui Wang and Jinyuan Jia},
  year          = {2024},
  eprint        = {2402.07867},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2402.07867}
}

@article{radford2019language,
  added-at = {2024-11-15T12:44:17.000+0100},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  biburl = {https://www.bibsonomy.org/bibtex/233e4b003b64b1060334660fbf6db1f3f/albinzehe},
  interhash = {b926ece39c03cdf5499f6540cf63babd},
  intrahash = {33e4b003b64b1060334660fbf6db1f3f},
  journal = {OpenAI},
  keywords = {gpt gpt2 languagemodelling transferlearning transformer},
  note = {Accessed: 2024-11-15},
  timestamp = {2024-11-15T12:44:17.000+0100},
  title = {Language Models are Unsupervised Multitask Learners},
  url = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
  year = 2019
}

@inproceedings{wahle-etal-2024-paraphrase,
    title = "Paraphrase Types Elicit Prompt Engineering Capabilities",
    author = "Wahle, Jan Philip  and
      Ruas, Terry  and
      Xu, Yang  and
      Gipp, Bela",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.617/",
    doi = "10.18653/v1/2024.emnlp-main.617",
    pages = "11004--11033",
    abstract = "Much of the success of modern language models depends on finding a suitable prompt to instruct the model. Until now, it has been largely unknown how variations in the linguistic expression of prompts affect these models. This study systematically and empirically evaluates which linguistic features influence models through paraphrase types, i.e., different linguistic changes at particular positions. We measure behavioral changes for five models across 120 tasks and six families of paraphrases (i.e., morphology, syntax, lexicon, lexico-syntax, discourse, and others). We also control for other prompt engineering factors (e.g., prompt length, lexical diversity, and proximity to training data). Our results show a potential for language models to improve tasks when their prompts are adapted in specific paraphrase types (e.g., 6.7{\%} median gain in Mixtral 8x7B; 5.5{\%} in LLaMA 3 8B). In particular, changes in morphology and lexicon, i.e., the vocabulary used, showed promise in improving prompts. These findings contribute to developing more robust language models capable of handling variability in linguistic expression."
}
